{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Platforms - Home Assignment 1\n",
    "## Omri Newman SID806646\n",
    "Due 13.11.2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.csv as csv\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Create local CSV file “mydata.csv”  with 1000000 rows with columns (id, fruit, price, color). Use random value for rows, where fruit has one of the values ['Orange', 'Grape', 'Apple', 'Banana', 'Pineapple', 'Avocado'] and colors are   ['Red', 'Green', 'Yellow', 'Blue']. Price should be random integer between 10 and 100. Filed id should be an index number starting from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mydata.csv already exists\n"
     ]
    }
   ],
   "source": [
    "def check_csv():\n",
    "    \"\"\"check if 'mydata.csv' exists in current working directory.\n",
    "    If not, create 'mydata.csv'.\n",
    "    \"\"\"\n",
    "    path = os.path.join(os.getcwd(), \"mydata.csv\")\n",
    "    if os.path.isfile(path):\n",
    "        print(\"mydata.csv already exists\")\n",
    "        pass\n",
    "    else:\n",
    "        index = range(1, 1000001)\n",
    "        cost = range(10, 101)\n",
    "        fruit = [random.choice(\n",
    "            [\"Orange\", \"Grape\", \"Apple\", \"Banana\", \"Pineapple\", \"Avocado\"]) for\n",
    "                 i in index]\n",
    "        price = [random.choice(cost) for i in index]\n",
    "        color = [random.choice([\"Red\", \"Green\", \"Yellow\", \"Blue\"]) for i in\n",
    "                 index]\n",
    "        df = pd.DataFrame(\n",
    "            {\"id\": index, \"fruit\": fruit, \"price\": price, \"color\": color})\n",
    "        df.to_csv(\"mydata.csv\", index=False)\n",
    "        print(\"creating mydata.csv\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    check_csv()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Python code to create SQLite database “mydb.db” and create a table “mydata” with the schema of the “mydata.csv” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite version: 2.6.0\n",
      "mydb.db already exists\n",
      "mydata already exists\n"
     ]
    }
   ],
   "source": [
    "def check_mydatabase():\n",
    "    \"\"\"check if 'mydb.db' database exists in current working directory. \n",
    "    If not, create it.\"\"\"\n",
    "    path = os.path.join(os.getcwd(), \"mydb.db\")\n",
    "    if os.path.isfile(path):\n",
    "        print(\"sqlite version: \" + str(sqlite3.version))\n",
    "        print(\"mydb.db already exists\")\n",
    "        pass\n",
    "    else:\n",
    "        conn = sqlite3.connect('mydb.db')\n",
    "        print(\"creating mydb.db\")\n",
    "        \n",
    "def check_mydata():\n",
    "    \"\"\"check if 'mydata' table exists in 'mydb.db' database. \n",
    "    If not, create it.\"\"\"\n",
    "    path = os.path.join(os.getcwd(), \"mydb.db\")\n",
    "    filesize = os.path.getsize(path)\n",
    "    if filesize != 0:\n",
    "        print(\"mydata already exists\")\n",
    "        pass\n",
    "    else:\n",
    "        conn = sqlite3.connect('mydb.db')\n",
    "        c = conn.cursor()\n",
    "        c.execute(''' CREATE TABLE mydata\n",
    "        (id INT,\n",
    "         fruit VARCHAR(20),\n",
    "         price INT,\n",
    "         color VARCHAR(20))\n",
    "        ''')\n",
    "        conn.commit()\n",
    "        print(\"creating mydata\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    check_mydatabase()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    check_mydata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Python code to load “mydata.csv” into “mydata” table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mydata.csv already loaded\n"
     ]
    }
   ],
   "source": [
    "def load_csv():\n",
    "    \"\"\"Check if 'mydata.csv' has been loaded into 'mydata' in 'mydb.db'. If not, append into the schema.\"\"\"\n",
    "    path = os.path.join(os.getcwd(), \"mydb.db\")\n",
    "    filesize = os.path.getsize(path)\n",
    "    if filesize < 14000000:\n",
    "        conn = sqlite3.connect('mydb.db')\n",
    "        df = pd.read_csv(\"mydata.csv\")\n",
    "        df.to_sql('mydata', conn, if_exists='append', index=False)\n",
    "        print(\"loading mydata.csv to mydata in mydb.db\")\n",
    "    else:\n",
    "        print(\"mydata.csv already loaded\")\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write 2 different SQL statements  with different conditions to retrieve different rows. Explain which parts of the statement are predicate and which parts are projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fruit</th>\n",
       "      <th>price</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>Pineapple</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>Avocado</td>\n",
       "      <td>10</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>Pineapple</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149</td>\n",
       "      <td>Pineapple</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>268</td>\n",
       "      <td>Pineapple</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>999676</td>\n",
       "      <td>Orange</td>\n",
       "      <td>100</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>999748</td>\n",
       "      <td>Avocado</td>\n",
       "      <td>100</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>999838</td>\n",
       "      <td>Apple</td>\n",
       "      <td>100</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>999869</td>\n",
       "      <td>Banana</td>\n",
       "      <td>100</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>999915</td>\n",
       "      <td>Avocado</td>\n",
       "      <td>100</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      fruit  price   color\n",
       "0           64  Pineapple     10  Yellow\n",
       "1           72    Avocado     10   Green\n",
       "2          126  Pineapple     10  Yellow\n",
       "3          149  Pineapple     10  Yellow\n",
       "4          268  Pineapple     10  Yellow\n",
       "...        ...        ...    ...     ...\n",
       "999995  999676     Orange    100     Red\n",
       "999996  999748    Avocado    100  Yellow\n",
       "999997  999838      Apple    100  Yellow\n",
       "999998  999869     Banana    100     Red\n",
       "999999  999915    Avocado    100  Yellow\n",
       "\n",
       "[1000000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Predicate refers to the where/filter clause which effects the amount of rows returned, and selects rows \n",
    "that specify a given logic. \n",
    "\n",
    "Projection refers to the selected columns when wanting to see a few attributes instead \n",
    "of all attributes.\n",
    "\n",
    "This query Selects all columns from mydata which is a Projection. It then orders all the rows according to \n",
    "their price, which is a Predicate.\"\"\"\n",
    "\n",
    "conn = sqlite3.connect('mydb.db')\n",
    "\n",
    "query = ('''SELECT * \n",
    "          FROM mydata\n",
    "          ORDER BY price ASC''')\n",
    "\n",
    "pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit</th>\n",
       "      <th>price</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>Banana</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>Banana</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>Banana</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>Banana</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7798</th>\n",
       "      <td>Banana</td>\n",
       "      <td>10</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981982</th>\n",
       "      <td>Banana</td>\n",
       "      <td>100</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989804</th>\n",
       "      <td>Banana</td>\n",
       "      <td>100</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992060</th>\n",
       "      <td>Banana</td>\n",
       "      <td>100</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995354</th>\n",
       "      <td>Banana</td>\n",
       "      <td>100</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998902</th>\n",
       "      <td>Banana</td>\n",
       "      <td>100</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41979 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fruit  price   color\n",
       "id                           \n",
       "864     Banana     10  Yellow\n",
       "1632    Banana     10  Yellow\n",
       "1926    Banana     10  Yellow\n",
       "6780    Banana     10  Yellow\n",
       "7798    Banana     10  Yellow\n",
       "...        ...    ...     ...\n",
       "981982  Banana    100  Yellow\n",
       "989804  Banana    100  Yellow\n",
       "992060  Banana    100  Yellow\n",
       "995354  Banana    100  Yellow\n",
       "998902  Banana    100  Yellow\n",
       "\n",
       "[41979 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Predicate refers to the where/filter clause which effects the amount of rows returned, and selects rows \n",
    "that specify a given logic. \n",
    "\n",
    "Projection refers to the selected columns when wanting to see a few attributes instead \n",
    "of all attributes.\n",
    "\n",
    "This query Selects all columns from mydata which is a Projection. But it selects a subset of rows, namely \n",
    "it returns fruit that start with the letter 'B' and colors that start with the letter 'Y', it then orders\n",
    "according to price - Predicate.\"\"\"\n",
    "\n",
    "conn = sqlite3.connect('mydb.db')\n",
    "\n",
    "query = ('''SELECT id, fruit, price, color \n",
    "          FROM mydata\n",
    "          WHERE fruit LIKE 'B%' AND color LIKE 'Y%'\n",
    "          ORDER BY price ASC''')\n",
    "\n",
    "pd.read_sql_query(query, conn, index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:  CSV and Parquet\n",
    "Write Python program that reads “mydata.csv” file and count number of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mydata.csv has 1000001 lines\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"mydata.csv\")\n",
    "print(\"mydata.csv has %d lines\" % (len(df)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using PyArrow, create Parquet file from the “mydata.csv”. Name Parquet file as “mydatapyarrow.parquet”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv.read_csv('mydata.csv')\n",
    "pq.write_table(df, 'mydatapyarrow.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Dask, create Parquet file from the “mydata.csv”. Name Parquet file as “mydatadask.parquet”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_csv('mydata.csv').set_index('id')\n",
    "df.to_parquet('mydatadask.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Pandas, create Parquet file from the “mydata.csv”. Name Parquet file as “mydatapandas.parquet”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mydata.csv\")\n",
    "df.to_parquet('mydatapandas.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine generated Parquet files.  Why do you think Dask generated Parquet file differently than PyArrow and Pandas? What might be explanation for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dask is written for parallel computing while PyArrow and Pandas are not which I imagine is why it generated \n",
    "the Parquet file differently. Dask turned the file into its own directory containing metadata from the file.* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Split CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Python code that calculates size of “mydata.csv” in bytes. Define an integer variable “middle” which is the size of “mydata.csv”  divided by 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mydata.csv has 22733982 bytes\n",
      "The middle 'byte' is 11366991\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), \"mydata.csv\")\n",
    "filesize = os.path.getsize(path)\n",
    "middle = filesize//2\n",
    "print(\"mydata.csv has %d bytes\" % (filesize))\n",
    "print(\"The middle 'byte' is %d\" % (middle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function first_chunk that count number of rows by reading the byte range of the CSV file, from 0 till the “middle”. Write a function last_chunk that count number of rows by reading byte range of CSV file from the “middle”+1 till the end of the file. Notice: Use seek to position into middle + 1 location. To correctly seek and read, you need to open file into binary mode and use decoder, for example to read the second chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_chunk(path):\n",
    "    filesize = os.path.getsize(path)\n",
    "    middle = int(filesize//2)\n",
    "    file = open(path, \"rb\")\n",
    "    r = file.read(middle+1).decode(encoding=\"utf-8\")\n",
    "    lst = r.split(\"\\n\")     \n",
    "    return len(lst)\n",
    "\n",
    "def second_chunk(path):\n",
    "    filesize = os.path.getsize(path)\n",
    "    middle = int(filesize//2)\n",
    "    file = open(path, \"rb\")\n",
    "    file.seek(middle+1)\n",
    "    r = file.read().decode(encoding=\"utf-8\")\n",
    "    lst = r.split(\"\\n\")\n",
    "    if len(lst[-1]) == 0:\n",
    "        lst.pop()\n",
    "    return len(lst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_chunk(\"mydata.csv\")+second_chunk(\"mydata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why total number of lines from the first chunk and second chunk is larger than the number of lines calculated in the step (1) of Task 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The number of lines from the first chunk and second chunk combined is larger than what was calculated in \n",
    "Task 2 because in most cases, the split line will be counted twice by both functions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggest an algorithm to resolve the issue from the step (3) and implement it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You could simply use the same algorithm but add an if statement in first_chunk() which checks if the middle byte \n",
    "is a new line character, and if so returns the len of the list. If not it returns the length of the list minus \n",
    "one since that will always reconcile the double count from the middle line.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_first_chunk(path):\n",
    "    filesize = os.path.getsize(path)\n",
    "    middle = int(filesize//2)\n",
    "    file = open(path, \"rb\")\n",
    "    r = file.read(middle+1).decode(encoding=\"utf-8\")\n",
    "    lst = r.split(\"\\n\")     \n",
    "    if len(lst[-1]) == 0:\n",
    "        lst.pop()\n",
    "        return len(lst)\n",
    "    return len(lst)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_first_chunk(\"mydata.csv\")+second_chunk(\"mydata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the algorithm of step (4) with multiple chunks. Define a chunk size to be 16MB. Write a function that process “mydata.csv “ in chunks and count number of lines for each chunk. For example, first chunk will be 0-16MB, second chunk 16MB-32BM, and so on, until the last chunk, which might be smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_chunks(path, size):\n",
    "    filesize = os.path.getsize(path)\n",
    "    complete_chunk = filesize//size\n",
    "    complete_lines = []\n",
    "    for i in range(complete_chunk): \n",
    "        file = open(path, \"rb\")  \n",
    "        file.seek(((i)*size))\n",
    "        r = file.read(size).decode(encoding=\"utf-8\")\n",
    "        lst = r.split(\"\\n\")\n",
    "        if len(lst[-1]) == 0:\n",
    "            lst.pop()\n",
    "            complete_lines.append(len(lst))\n",
    "        else:\n",
    "            complete_lines.append(len(lst)-1) \n",
    "    return sum(complete_lines), complete_chunk\n",
    "\n",
    "def sub_chunk(path, size):\n",
    "    filesize = os.path.getsize(path)\n",
    "    complete_chunk = filesize//size\n",
    "    sub_chunk = filesize%size\n",
    "    file = open(path, \"rb\")\n",
    "    file.seek(int(complete_chunk*size)+1)\n",
    "    r = file.read().decode(encoding=\"utf-8\")\n",
    "    lst = r.split(\"\\n\")\n",
    "    if len(lst[-1]) == 0:\n",
    "        lst.pop()\n",
    "    return len(lst), sub_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1 complete 16mb chunk in mydata.csv, which consist of 705160 lines out of 1000001\n"
     ]
    }
   ],
   "source": [
    "complete_chunks(\"mydata.csv\", 16000000)\n",
    "print(\"There is %d complete 16mb chunk in mydata.csv, which consist of %d lines out of 1000001\" % \n",
    "      (complete_chunks(\"mydata.csv\", 16000000)[1], complete_chunks(\"mydata.csv\", 16000000)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remaining chunk consists of 6733982 bytes and accounts for 294841 lines out of 1000001\n"
     ]
    }
   ],
   "source": [
    "print(\"The remaining chunk consists of %d bytes and accounts for %d lines out of 1000001\" %\n",
    "     (sub_chunk(\"mydata.csv\", 16000000)[1], sub_chunk(\"mydata.csv\", 16000000)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The bytes add up to the filesize \n",
    "(16000000+sub_chunk(\"mydata.csv\", 16000000)[1]) == os.path.getsize(\"mydata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_chunks(\"mydata.csv\", 16000000)[0] + sub_chunk(\"mydata.csv\", 16000000)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the above function on other chunk sizes.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 complete 5mb chunks in mydata.csv which consist of 880330 out of 1000001 lines\n"
     ]
    }
   ],
   "source": [
    "complete_chunks(\"mydata.csv\", 5000000)\n",
    "print(\"There are %d complete 5mb chunks in mydata.csv which consist of %d out of 1000001 lines\" % \n",
    "      (complete_chunks(\"mydata.csv\", 5000000)[1], complete_chunks(\"mydata.csv\", 5000000)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remaining chunk consists of 2733982 bytes and accounts for 119671 lines out of 1000001\n"
     ]
    }
   ],
   "source": [
    "print(\"The remaining chunk consists of %d bytes and accounts for %d lines out of 1000001\" %\n",
    "     (sub_chunk(\"mydata.csv\", 5000000)[1], sub_chunk(\"mydata.csv\", 5000000)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_chunks(\"mydata.csv\", 5000000)[0] + sub_chunk(\"mydata.csv\", 5000000)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
